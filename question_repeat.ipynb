{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/q_repeat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "# import json\n",
    "\n",
    "api_key = \"YOUR API KEY\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpotqa_dataset = load_dataset('hotpotqa/hotpot_qa', 'fullwiki', trust_remote_code=True)\n",
    "squad_dataset = load_dataset('rajpurkar/squad', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NQ -- but annoying to process\n",
    "# file_path = \"datasets/v1.0-simplified_nq-dev-all.jsonl\"\n",
    "\n",
    "# # Reading the file\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     for line in file:\n",
    "#         # Parse the JSON line\n",
    "#         data = json.loads(line)\n",
    "#         # Print or process the parsed data\n",
    "#         print(data)  # Replace this with your processing logic\n",
    "#         question = data['question_text']\n",
    "#         context = data['context']\n",
    "#         answers = data['answers']['text']\n",
    "\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_num = 500\n",
    "repeats = [1, 3, 5]\n",
    "# models = ['gpt-4o-mini', \"gpt-4o-mini-2024-07-18\"]\n",
    "models = ['gpt-4o-mini-2024-07-18']\n",
    "\n",
    "# Global dictionary to save results\n",
    "overall_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results structure for each model with separate dataset contexts\n",
    "for model in models:\n",
    "    overall_results[model] = {\n",
    "        \"hotpotqa\": {\n",
    "            \"with_context\": {},\n",
    "            \"without_context\": {}\n",
    "        },\n",
    "        \"squad\": {\n",
    "            \"with_context\": {},\n",
    "            \"without_context\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Evaluate HotPotQA with and without context\n",
    "for model in models:\n",
    "    # Process \"with context\" for hotpotqa\n",
    "    for repeat in repeats:\n",
    "        hotpotqa_results_w_context = []\n",
    "        for idx, entry in enumerate(hotpotqa_dataset['validation']):\n",
    "            if idx == questions_num:\n",
    "                break\n",
    "            question = entry['question']\n",
    "            context_sentences = [\" \".join(sentence) for sentence in entry['context']['sentences']]\n",
    "            context = \" \".join(context_sentences)\n",
    "            answer = entry['answer']\n",
    "            prompt = f'Context: {context} ' + f'Question: {question} ' * repeat + 'Answer: '\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            hotpotqa_results_w_context.append([completion.choices[0].message.content, answer])\n",
    "        \n",
    "        corrects = sum(1 for r in hotpotqa_results_w_context if r[1].lower() in r[0].lower())\n",
    "        \n",
    "        # Save results specific to hotpotqa with context\n",
    "        overall_results[model]['hotpotqa']['with_context'][f\"Qx{repeat}\"] = {\n",
    "            \"results\": hotpotqa_results_w_context,\n",
    "            \"corrects\": corrects,\n",
    "            \"accuracy\": corrects / len(hotpotqa_results_w_context) if hotpotqa_results_w_context else 0\n",
    "        }\n",
    "\n",
    "    # Process \"without context\" for hotpotqa\n",
    "    for repeat in repeats:\n",
    "        hotpotqa_results_wo_context = []\n",
    "        for idx, entry in enumerate(hotpotqa_dataset['validation']):\n",
    "            if idx == questions_num:\n",
    "                break\n",
    "            question = entry['question']\n",
    "            answer = entry['answer']\n",
    "            prompt = f'Question: {question} ' * repeat + 'Answer: '\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            hotpotqa_results_wo_context.append([completion.choices[0].message.content, answer])\n",
    "        \n",
    "        corrects = sum(1 for r in hotpotqa_results_wo_context if r[1].lower() in r[0].lower())\n",
    "\n",
    "        # Save results specific to hotpotqa without context\n",
    "        overall_results[model]['hotpotqa']['without_context'][f\"Qx{repeat}\"] = {\n",
    "            \"results\": hotpotqa_results_wo_context,\n",
    "            \"corrects\": corrects,\n",
    "            \"accuracy\": corrects / len(hotpotqa_results_wo_context) if hotpotqa_results_wo_context else 0\n",
    "        }\n",
    "\n",
    "# Evaluate Squad with and without context\n",
    "for model in models:\n",
    "    # Process \"with context\" for squad\n",
    "    for repeat in repeats:\n",
    "        squad_results_w_context = []\n",
    "        for idx, entry in enumerate(squad_dataset):\n",
    "            if idx == questions_num:\n",
    "                break\n",
    "            question = entry['question']\n",
    "            context = entry['context']\n",
    "            answer = entry['answers']['text']  # This is a list of correct answers\n",
    "            prompt = f'Context: {context} ' + f'Question: {question} ' * repeat + 'Answer: '\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            squad_results_w_context.append([completion.choices[0].message.content, answer])\n",
    "        \n",
    "        # Correct responses calculation using your logic\n",
    "        corrects = 0\n",
    "        for r in squad_results_w_context:\n",
    "            generated_ans, ans = r[0], r[1]  # r[0] is model-generated response, r[1] is the list of correct answers\n",
    "            if any(item.lower() in generated_ans.lower() for item in ans):\n",
    "                corrects += 1\n",
    "\n",
    "        # Save results specific to squad with context\n",
    "        overall_results[model]['squad']['with_context'][f\"Qx{repeat}\"] = {\n",
    "            \"results\": squad_results_w_context,\n",
    "            \"corrects\": corrects,\n",
    "            \"accuracy\": corrects / len(squad_results_w_context) if squad_results_w_context else 0\n",
    "        }\n",
    "\n",
    "    # Process \"without context\" for squad\n",
    "    for repeat in repeats:\n",
    "        squad_results_wo_context = []\n",
    "        for idx, entry in enumerate(squad_dataset):\n",
    "            if idx == questions_num:\n",
    "                break\n",
    "            question = entry['question']\n",
    "            answer = entry['answers']['text']  # This is a list of correct answers\n",
    "            prompt = f'Question: {question} ' * repeat + 'Answer: '\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            squad_results_wo_context.append([completion.choices[0].message.content, answer])\n",
    "\n",
    "        # Correct responses calculation using your logic\n",
    "        corrects = 0\n",
    "        for r in squad_results_wo_context:\n",
    "            generated_ans, ans = r[0], r[1]  # r[0] is model-generated response, r[1] is the list of correct answers\n",
    "            if any(item.lower() in generated_ans.lower() for item in ans):\n",
    "                corrects += 1\n",
    "\n",
    "        # Save results specific to squad without context\n",
    "        overall_results[model]['squad']['without_context'][f\"Qx{repeat}\"] = {\n",
    "            \"results\": squad_results_wo_context,\n",
    "            \"corrects\": corrects,\n",
    "            \"accuracy\": corrects / len(squad_results_wo_context) if squad_results_wo_context else 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini-2024-07-18\n",
      "\n",
      "# With context:\n",
      "hotpotqa:\n",
      "  Standard accuracy (Qx1): 0.58\n",
      "  Repeat x3 accuracy (Qx3): 0.58\n",
      "  Repeat x5 accuracy (Qx5): 0.59\n",
      "\n",
      "# Without context:\n",
      "hotpotqa:\n",
      "  Standard accuracy (Qx1): 0.42\n",
      "  Repeat x3 accuracy (Qx3): 0.42\n",
      "  Repeat x5 accuracy (Qx5): 0.43\n",
      "\n",
      "# With context:\n",
      "squad:\n",
      "  Standard accuracy (Qx1): 0.99\n",
      "  Repeat x3 accuracy (Qx3): 0.99\n",
      "  Repeat x5 accuracy (Qx5): 0.98\n",
      "\n",
      "# Without context:\n",
      "squad:\n",
      "  Standard accuracy (Qx1): 0.49\n",
      "  Repeat x3 accuracy (Qx3): 0.49\n",
      "  Repeat x5 accuracy (Qx5): 0.49\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over models to print results for each\n",
    "for model_name, model_results in overall_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print()\n",
    "    for dataset_name, settings in model_results.items():\n",
    "        # Print context settings for each dataset\n",
    "        print(f\"# With context:\")\n",
    "        print(f\"{dataset_name}:\")\n",
    "        print(f\"  Standard accuracy (Qx1): {settings['with_context']['Qx1']['accuracy']:.2f}\")\n",
    "        print(f\"  Repeat x3 accuracy (Qx3): {settings['with_context']['Qx3']['accuracy']:.2f}\")\n",
    "        print(f\"  Repeat x5 accuracy (Qx5): {settings['with_context']['Qx5']['accuracy']:.2f}\")\n",
    "        print()\n",
    "        # Print without context settings for each dataset\n",
    "        print(f\"# Without context:\")\n",
    "        print(f\"{dataset_name}:\")\n",
    "        print(f\"  Standard accuracy (Qx1): {settings['without_context']['Qx1']['accuracy']:.2f}\")\n",
    "        print(f\"  Repeat x3 accuracy (Qx3): {settings['without_context']['Qx3']['accuracy']:.2f}\")\n",
    "        print(f\"  Repeat x5 accuracy (Qx5): {settings['without_context']['Qx5']['accuracy']:.2f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q_repeat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
